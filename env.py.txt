# env.py
import gym
from gym import spaces
import numpy as np
import pandas as pd

class TradingEnv(gym.Env):
    """
    Simple trading env:
    - observation = [normalized price window + indicators]
    - actions: 0 = hold, 1 = long, 2 = short (we'll keep simple)
    - reward: PnL change
    """
    metadata = {"render.modes": ["human"]}

    def __init__(self, df: pd.DataFrame, window_size: int=50, initial_balance: float=10000):
        super().__init__()
        self.df = df.reset_index(drop=True)
        self.window_size = window_size
        self.initial_balance = initial_balance
        self.current_step = window_size
        self.done = False
        # observation: window_size closes + indicators (rsi, ema20, ema50)
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(window_size + 3,), dtype=np.float32)
        self.action_space = spaces.Discrete(3)
        self.reset()

    def reset(self):
        self.balance = self.initial_balance
        self.position = 0.0  # positive for long size, negative for short size
        self.entry_price = 0.0
        self.current_step = self.window_size
        self.done = False
        return self._get_obs()

    def _get_obs(self):
        window = self.df["close"].iloc[self.current_step - self.window_size : self.current_step].values
        norm = (window - np.mean(window)) / (np.std(window) + 1e-9)
        latest = self.df.iloc[self.current_step]
        indicators = np.array([latest["rsi"], latest["ema20"], latest["ema50"]])
        return np.concatenate([norm, indicators]).astype(np.float32)

    def step(self, action):
        # action: 0 hold, 1 long, 2 short
        price = self.df["close"].iloc[self.current_step]
        reward = 0.0

        # simple logic: opening/closing single position
        if action == 1:  # go long
            if self.position == 0:
                self.position = 1
                self.entry_price = price
        elif action == 2:  # go short
            if self.position == 0:
                self.position = -1
                self.entry_price = price
        else:  # hold: we might close based on some rule (left simple)
            pass

        # compute unrealized PnL
        pnl = 0.0
        if self.position != 0:
            pnl = (price - self.entry_price) * self.position

        reward = pnl / (self.initial_balance + 1e-9)

        self.current_step += 1
        if self.current_step >= len(self.df) - 1:
            self.done = True

        obs = self._get_obs()
        info = {"price": price, "position": self.position}
        return obs, reward, self.done, info

    def render(self, mode="human"):
        pass
